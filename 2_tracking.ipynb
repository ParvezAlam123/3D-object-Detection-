{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fc60d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import time \n",
    "import numba \n",
    "import open3d as o3d \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from  torch.optim.lr_scheduler import StepLR\n",
    "import open3d as o3d \n",
    "import numpy as np \n",
    "import os \n",
    "import struct \n",
    "from tqdm import tqdm \n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d91686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoxelGenerator:\n",
    "    def __init__(self,\n",
    "                 voxel_size,\n",
    "                 point_cloud_range,\n",
    "                 max_num_points=35, \n",
    "                 max_voxels=20000):\n",
    "        point_cloud_range = np.array(point_cloud_range, dtype=np.float32) \n",
    "        # [0, -40, -3, 70.4, 40, 1]\n",
    "        voxel_size = np.array(voxel_size, dtype=np.float32)\n",
    "        grid_size = (point_cloud_range[3:] - point_cloud_range[:3]) / voxel_size \n",
    "        grid_size = np.round(grid_size).astype(np.int64)\n",
    "\n",
    "\n",
    "        self._voxel_size = voxel_size \n",
    "        self._point_cloud_range = point_cloud_range \n",
    "        self._max_num_points = max_num_points \n",
    "        self._max_voxels = max_voxels \n",
    "        self._grid_size = grid_size \n",
    "\n",
    "    def generate(self, points, max_voxels):\n",
    "        return points_to_voxel(points, self._voxel_size, self._point_cloud_range, self._max_num_points, True, max_voxels)\n",
    "    \n",
    "    @property\n",
    "    def voxel_size(self):\n",
    "        return self._voxel_size \n",
    "    \n",
    "\n",
    "    @property \n",
    "    def max_num_points_per_voxel(self):\n",
    "        return self._max_num_points \n",
    "    \n",
    "    @property \n",
    "    def point_cloud_range(self):\n",
    "        return self._point_cloud_range \n",
    "    \n",
    "    @property \n",
    "    def grid_size(self):\n",
    "        return self._grid_size \n",
    "    \n",
    "\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def _points_to_voxel_reverse_kernel(points, \n",
    "                                    voxel_size, \n",
    "                                    coors_range,\n",
    "                                    num_points_per_voxel,\n",
    "                                    coor_to_voxelidx,\n",
    "                                    voxels,\n",
    "                                    coors,\n",
    "                                    max_points=35,\n",
    "                                    max_voxels=20000):\n",
    "    # put all the computation in one loop.\n",
    "    # we should not create large array in main jit code, otherwise reduce performance.\n",
    "    N = points.shape[0]\n",
    "    #ndim = points.shape[1] - 1 \n",
    "    ndim = 3 \n",
    "    ndim_minus_1 = ndim -  1\n",
    "    grid_size = (coors_range[3:] - coors_range[:3]) / voxel_size \n",
    "    #np.round(grid_size)\n",
    "    #grid_size = np.round(grid_size).astype(np.int64)(np.int32)\n",
    "    grid_size = np.round(grid_size, 0, grid_size).astype(np.int32)\n",
    "    coor = np.zeros(shape=(3, ), dtype=np.int32)\n",
    "    voxel_num = 0\n",
    "    failed = False \n",
    "    for i in range(N):\n",
    "        failed = False \n",
    "        for j in range(ndim):\n",
    "            c = np.floor((points[i, j] - coors_range[j]) / voxel_size[j])\n",
    "            if c < 0 or c >= grid_size[j]:\n",
    "                failed = True \n",
    "                break \n",
    "            coor[ndim_minus_1 - j] = c \n",
    "        if failed:\n",
    "            continue \n",
    "        voxelidx = coor_to_voxelidx[coor[0], coor[1], coor[2]]\n",
    "        if voxelidx == -1:\n",
    "            voxelidx = voxel_num \n",
    "            if voxel_num >= max_voxels:\n",
    "                break \n",
    "            voxel_num += 1 \n",
    "            coor_to_voxelidx[coor[0], coor[1], coor[2]] = voxelidx \n",
    "            coors[voxelidx] = coor \n",
    "        num = num_points_per_voxel[voxelidx]\n",
    "        if num < max_points:\n",
    "            voxels[voxelidx, num] = points[i]\n",
    "            num_points_per_voxel[voxelidx] += 1\n",
    "        \n",
    "    return voxel_num, coors, voxels, num_points_per_voxel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def _points_to_voxel_kernel(points, \n",
    "                            voxel_size,\n",
    "                            coors_range,\n",
    "                            num_points_per_voxel, \n",
    "                            coor_to_voxelidx, \n",
    "                            voxels,\n",
    "                            coors,\n",
    "                            max_points=35,\n",
    "                            max_voxels=20000):\n",
    "    #need mutex if write cuda but numba.cuda don't support mutex.\n",
    "    # in addition pytorch don't support cuda in dataloader.\n",
    "    # put all the computation in  one loop \n",
    "    # We should not create large array in main jit code, otherwise decrease performance.\n",
    "    N = points.shape[0]\n",
    "    # ndim = points.shape[1] - 1\n",
    "    ndim = 3 \n",
    "    grid_size = (coors_range[3:] - coors_range[:3]) / voxel_size \n",
    "    #  grid_size = np.round(grid_size).astype(np.float64)(np.float32)\n",
    "    grid_size = np.round(grid_size, 0, grid_size).astype(np.int32)\n",
    "\n",
    "    lower_bounnd = coors_range[:3]\n",
    "    upper_bound = coors_range[3:]\n",
    "    coor = np.zeros(shape=(3,), dtype=np.int32)\n",
    "    voxel_num = 0\n",
    "    failed = False \n",
    "    for i in range(N):\n",
    "        failed = False \n",
    "        for j in range(ndim):\n",
    "            c = np.floor((points[i, j] - coors_range[j]) / voxel_size[j])\n",
    "            if c < 0 or c >= grid_size[j]:\n",
    "                failed = True \n",
    "                break \n",
    "            coor[j] = c \n",
    "        if failed:\n",
    "            continue \n",
    "        voxelidx = coor_to_voxelidx[coor[0], coor[1], coor[2]]\n",
    "        if voxelidx == -1:\n",
    "            voxelidx = voxel_num \n",
    "            if voxel_num >= max_voxels:\n",
    "                break \n",
    "            voxel_num += 1 \n",
    "            coor_to_voxelidx[coor[0], coor[1], coor[2]] = voxelidx \n",
    "            coors[voxelidx] = coor \n",
    "        num = num_points_per_voxel[voxelidx]\n",
    "        if num < max_points:\n",
    "            voxels[voxelidx, num] = points[i]\n",
    "            num_points_per_voxel[voxelidx] += 1 \n",
    "\n",
    "    \n",
    "    return voxel_num, coors, voxels, num_points_per_voxel \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def points_to_voxel(points, voxel_size, coors_range, max_points=35, reverse_index=True, max_voxels=20000):\n",
    "    \"\"\"\n",
    "    convert kitti points (N, >=3)  to voxels. This version calculate everything in one loop. Now it takes only 4.2 ms (complete point cloud) with JIT.\n",
    "    (Don't calculate other features).\n",
    "    Note: this function in ubuntu seems faster than window 10.\n",
    "    Args:\n",
    "       points: [N, ndim] float tensor.points[:, :3] contain xyz points and points[:, 3:] contain other information such as reflectivity.\n",
    "       voxel_size : [3] list/tuple or array. float.xyz indicate voxel size.\n",
    "       coors_range: [6] list/tuple/array, float. indicate voxel range. format xyzxyz, minmax.\n",
    "       max_points:int. indicate maximum points contain in voxel.\n",
    "       reverse_index. boolean. indicate wheather return reverse coordinates.\n",
    "              If points has xyz format and reverse index is True, output coordinate will be zyx format, but points in features always in xyz format.\n",
    "       max_voxels: int. indicate maximum voxels this function create. \n",
    "             for SECOND 20000 is a good choice. You should shuffle points before call this function because max_voxels may drop some points.\n",
    "    Returns:\n",
    "       voxels: [M, max_points, ndim] float tensor. Only contain points.\n",
    "       coordinates: [M, 3]. int32 tensor.\n",
    "       num_points_per_voxel: [M] int32 tensor.\n",
    "        \n",
    "    \"\"\"\n",
    "    if not isinstance(voxel_size, np.ndarray):\n",
    "        voxel_size = np.array(voxel_size, dytpe=points.dtype)\n",
    "    if not isinstance(coors_range, np.ndarray):\n",
    "        coors_range = np.array(coors_range, dtype=points.dtype)\n",
    "    voxelmap_shape = (coors_range[3:] - coors_range[:3]) / voxel_size \n",
    "    voxelmap_shape = tuple(np.round(voxelmap_shape).astype(np.int32).tolist())\n",
    "    if reverse_index:\n",
    "        voxelmap_shape = voxelmap_shape[::-1]\n",
    "    # don't create large array in jit(nopython=True) code.\n",
    "    num_points_per_voxel = np.zeros(shape=(max_voxels, ), dtype=np.int32)\n",
    "    coor_to_voxelidx = -np.ones(shape=voxelmap_shape, dtype=np.int32)\n",
    "    voxels = np.zeros(shape=(max_voxels, max_points, points.shape[-1]), dtype=points.dtype)\n",
    "    coors = np.zeros(shape=(max_voxels,  3), dtype=np.int32)\n",
    "    if reverse_index:\n",
    "        voxel_num, coors, voxels, num_points_per_voxel = _points_to_voxel_reverse_kernel(\n",
    "            points, voxel_size, coors_range, num_points_per_voxel, coor_to_voxelidx, voxels, coors, max_points, max_voxels\n",
    "        )\n",
    "    else:\n",
    "        voxel_num, coors, voxels, num_points_per_voxel = _points_to_voxel_kernel(\n",
    "            points, voxel_size, coors_range, num_points_per_voxel, coor_to_voxelidx, voxels, coors, max_points, max_voxels\n",
    "        )\n",
    "\n",
    "    #coors = coors[:voxel_num]\n",
    "    #voxels = voxels[:voxel_num]\n",
    "    #num_points_per_voxel =  num_points_per_voxel[:voxel_num]\n",
    "    # voxels[:, :, -3:] = voxels[:, :, :3] - voxels[:, :, :3].sum(axis=1, keepdims=True) /num_points_per_voxel.reshape(-1,, 1,1)\n",
    "    return voxels, coors, num_points_per_voxel \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#voxel_generator = VoxelGenerator(voxel_size=[0.4, 0.4, 0.4], point_cloud_range=[0, -40, -3, 70.4, 40, 1])\n",
    "\n",
    "\n",
    "#path = \"/media/parvez_alam/Expansion/Dataset/training/SteeringData/1671529879.462312222.pcd\"\n",
    "\n",
    "#pcd = o3d.io.read_point_cloud(path)\n",
    "#points = np.asarray(pcd.points)\n",
    "\n",
    "\n",
    "#voxels,  coors, num_points_per_voxel = voxel_generator.generate(points, 20000)\n",
    "#print(\"voxels shape = \", voxels.shape)\n",
    "#print(\"coors shape = \", coors.shape)\n",
    "#print(\"num_points_per_voxel shape = \", num_points_per_voxel.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78cb27e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/parvez_alam/Data/Kitti/Tracking/data_tracking_velodyne/training/velodyne\"\n",
    "calib_path = \"/home/parvez_alam/Data/Kitti/Tracking/data_tracking_calib/training/calib\"\n",
    "label_path = \"/home/parvez_alam/Data/Kitti/Tracking/data_tracking_label_2/training/label_02\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6f68639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kitti_calib(calib_file):\n",
    "   \n",
    "    with open(calib_file) as f_calib:\n",
    "        lines = f_calib.readlines()\n",
    "      \n",
    "    P0 = np.array(lines[0].strip('\\n').split()[1:], dtype=np.float32)\n",
    "    P1 = np.array(lines[1].strip('\\n').split()[1:], dtype=np.float32)\n",
    "    P2 = np.array(lines[2].strip('\\n').split()[1:], dtype=np.float32)\n",
    "    P3 = np.array(lines[3].strip('\\n').split()[1:], dtype=np.float32)\n",
    "    R0_rect = np.array(lines[4].strip('\\n').split()[1:], dtype=np.float32)\n",
    "    Tr_velo_to_cam = np.array(lines[5].strip('\\n').split()[1:], dtype=np.float32)\n",
    "    Tr_imu_to_velo = np.array(lines[6].strip('\\n').split()[1:], dtype=np.float32) \n",
    "   \n",
    "    return {'P0': P0, 'P1':P1, 'P2':P2, 'P3':P3, 'R0_rect': R0_rect, 'Tr_velo_to_cam': Tr_velo_to_cam.reshape(3,4), 'Tr_imu_to_velo': Tr_imu_to_velo}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d64c64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_coordinate_to_point_cloud(box3d, Tr):\n",
    "\n",
    "    def project_cam2velo(cam, Tr):\n",
    "        T = np.zeros([4,4], dtype=np.float32)\n",
    "        T[:3, :] = Tr \n",
    "        T[3, 3] = 1 \n",
    "     \n",
    "        T_inv = np.linalg.inv(T) \n",
    "        lidar_loc_ = np.dot(T_inv, cam) \n",
    "        lidar_loc = lidar_loc_[:3]\n",
    "      \n",
    "        return lidar_loc.reshape(1,3) \n",
    "      \n",
    "    def ry_to_rz(ry):\n",
    "        angle = -ry - np.pi / 2\n",
    "      \n",
    "        if angle >= np.pi:\n",
    "           angle -= np.pi \n",
    "        if angle < -np.pi:\n",
    "           angle = 2 * np.pi + angle \n",
    "        return angle \n",
    "      \n",
    "      \n",
    "      \n",
    "   \n",
    "    h,w,l,tx,ty,tz,ry = [float(i) for i in box3d]\n",
    "    cam = np.ones([4,1])\n",
    "    cam[0] = tx \n",
    "    cam[1] = ty\n",
    "    cam[2] = tz \n",
    "    t_lidar = project_cam2velo(cam, Tr) \n",
    "  \n",
    "   \n",
    "    Box = np.array([[-l/2, -l/2, l/2, l/2, -l/2, -l/2, l/2, l/2],\n",
    "                   [w/2, -w/2, -w/2, w/2, w/2, -w/2, -w/2, w/2],\n",
    "                   [0, 0, 0, 0, h, h,  h, h]])\n",
    "                   \n",
    "    rz = ry_to_rz(ry) \n",
    "   \n",
    "    rotMat = np.array([[np.cos(rz), -np.sin(rz), 0.0],\n",
    "                       [np.sin(rz), np.cos(rz), 0.0],\n",
    "                       [0.0,          0.0,       1.0]])\n",
    "   \n",
    "                      \n",
    "    velo_box = np.dot(rotMat, Box) \n",
    "     \n",
    "    cornerPosInVelo = velo_box + np.tile(t_lidar, (8, 1)).T \n",
    "   \n",
    "    box3d_corner = cornerPosInVelo.transpose() \n",
    "   \n",
    "    return t_lidar, box3d_corner , rz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5155ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KITTIDATA(Dataset):\n",
    "    def __init__(self, data_path, label_path, calib_path, train=True):\n",
    "        self.data_path = data_path \n",
    "        self.label_path = label_path \n",
    "        self.calib_path = calib_path \n",
    "\n",
    "        self.scenes = sorted(os.listdir(self.data_path))\n",
    "        self.labels = sorted(os.listdir(self.label_path))\n",
    "        self.calibs = sorted(os.listdir(self.calib_path))\n",
    "\n",
    "        self.train_scenes = self.scenes[0:17]\n",
    "        self.test_scenes = self.scenes[17:21]\n",
    "\n",
    "        # object for voxelization \n",
    "        self.voxel_generator = VoxelGenerator(voxel_size=[0.4, 0.4, 0.4], point_cloud_range=[0, -40, -3, 70.4, 40, 1]) \n",
    "\n",
    "        \n",
    "        self.files = [] \n",
    "\n",
    "\n",
    "        if train == True :\n",
    "            for i in tqdm(range(len(self.train_scenes))):\n",
    "                pcd_file_path = os.path.join(self.data_path, self.scenes[i])\n",
    "                calib_file = os.path.join(self.calib_path, self.calibs[i])\n",
    "                label_file = os.path.join(self.label_path, self.labels[i])\n",
    "\n",
    "                calibration = load_kitti_calib(calib_file)\n",
    "\n",
    "                # get the total number of frames in particulat scenes \n",
    "                num_frames = len(os.listdir(pcd_file_path))\n",
    "\n",
    "                bb_list = []            # store bounding boxex of complete scene \n",
    "    \n",
    "                with open(label_file) as f_label:\n",
    "                    lines = f_label.readlines()\n",
    "       \n",
    "                    for line in lines:\n",
    "                       line = line.strip('\\n').split() \n",
    "                       if line[2] != 'DontCare':\n",
    "                            frame_index = line[0]             # frame number\n",
    "                            track_id = line[1]                # track ID\n",
    "                            category = line[2]                # class of the BB \n",
    "                            center, box3d_corner, rz = camera_coordinate_to_point_cloud(line[10:17], calibration['Tr_velo_to_cam'])\n",
    "                            center = center[0] \n",
    "                            bb_list.append([frame_index, center, box3d_corner, rz, category, track_id])\n",
    "                pcd_frames = sorted(os.listdir(pcd_file_path)) \n",
    "    \n",
    "                for n in range(len(pcd_frames)):\n",
    "                   pcd_path = os.path.join(pcd_file_path, pcd_frames[n])\n",
    "                   size_float = 4 \n",
    "                   list_pcd = [] \n",
    "                   with open(pcd_path, \"rb\") as f:\n",
    "                      byte = f.read(size_float * 4) \n",
    "                      while byte:\n",
    "                         x, y, z, intensity = struct.unpack(\"ffff\", byte) \n",
    "                         list_pcd.append([x,y,z]) \n",
    "                         byte = f.read(size_float * 4) \n",
    "\n",
    "                   points = np.asarray(list_pcd) \n",
    "\n",
    "                   #pcd = o3d.geometry.PointCloud() \n",
    "                   #pcd.points = o3d.utility.Vector3dVector(points) \n",
    "       \n",
    "       \n",
    "                   bboxes = [] \n",
    "                   for k in range(len(bb_list)):\n",
    "                       if int(bb_list[k][0]) == n : \n",
    "                          bboxes.append([bb_list[k][1], bb_list[k][2], bb_list[k][3], bb_list[k][4], bb_list[k][5]])   # [center, BB,rz, cetegory, track_id]\n",
    "\n",
    "                    \n",
    "                   sample = {}\n",
    "                   sample['pcd'] = points \n",
    "                   sample['labels'] = bboxes \n",
    "                   self.files.append(sample)\n",
    "\n",
    "        else:\n",
    "            for i in tqdm(range(len(self.test_scenes))):\n",
    "                pcd_file_path = os.path.join(self.data_path, self.scenes[i])\n",
    "                calib_file = os.path.join(self.calib_path, self.calibs[i])\n",
    "                label_file = os.path.join(self.label_path, self.labels[i])\n",
    "\n",
    "                calibration = load_kitti_calib(calib_file)\n",
    "\n",
    "                # get the total number of frames in particulat scenes \n",
    "                num_frames = len(os.listdir(pcd_file_path))\n",
    "\n",
    "                bb_list = []            # store bounding boxex of complete scene \n",
    "    \n",
    "                with open(label_file) as f_label:\n",
    "                    lines = f_label.readlines()\n",
    "       \n",
    "                    for line in lines:\n",
    "                       line = line.strip('\\n').split() \n",
    "                       if line[2] != 'DontCare':\n",
    "                          frame_index = line[0]             # frame number\n",
    "                          track_id = line[1]                # track ID\n",
    "                          category = line[2]                # class of the BB \n",
    "                          center, box3d_corner, rz = camera_coordinate_to_point_cloud(line[10:17], calibration['Tr_velo_to_cam'])\n",
    "                          center = center[0] \n",
    "                          bb_list.append([frame_index, center, box3d_corner,rz, category, track_id])\n",
    "                pcd_frames = sorted(os.listdir(pcd_file_path)) \n",
    "    \n",
    "                for n in range(len(pcd_frames)):\n",
    "                   pcd_path = os.path.join(pcd_file_path, pcd_frames[n])\n",
    "                   size_float = 4 \n",
    "                   list_pcd = [] \n",
    "                   with open(pcd_path, \"rb\") as f:\n",
    "                      byte = f.read(size_float * 4) \n",
    "                      while byte:\n",
    "                         x, y, z, intensity = struct.unpack(\"ffff\", byte) \n",
    "                         list_pcd.append([x,y,z]) \n",
    "                         byte = f.read(size_float * 4) \n",
    "\n",
    "                   points = np.asarray(list_pcd) \n",
    "\n",
    "                   #pcd = o3d.geometry.PointCloud() \n",
    "                   #pcd.points = o3d.utility.Vector3dVector(points) \n",
    "       \n",
    "       \n",
    "                   bboxes = [] \n",
    "                   for k in range(len(bb_list)):\n",
    "                       if int(bb_list[k][0]) == n : \n",
    "                          bboxes.append([bb_list[k][1], bb_list[k][2], bb_list[k][3], bb_list[k][4], bb_list[k][5]])   # [center, BB,rz,cate, track_id]\n",
    "\n",
    "                    \n",
    "                   sample = {}\n",
    "                   sample['pcd'] = points \n",
    "                   sample['labels'] = bboxes \n",
    "                   self.files.append(sample)\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "       return len(self.files) \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "       pcd = self.files[index]['pcd']\n",
    "       bboxes = self.files[index]['labels']\n",
    "       \n",
    "       # voxelize the point cloud \n",
    "       voxels, coors, num_points_per_voxel = self.voxel_generator.generate(pcd,20000)\n",
    "\n",
    "       return {'voxels':voxels, 'coors':coors, 'bboxes':bboxes}\n",
    "    \n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394490ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▌                                         | 1/17 [00:37<10:06, 37.93s/it]"
     ]
    }
   ],
   "source": [
    "train_ds = KITTIDATA(data_path=data_path, label_path=label_path, calib_path=calib_path, train=True)\n",
    "train_loader = DataLoader(dataset=train_ds, batch_size=1, shuffle=False )\n",
    "print(\"total_frames=\", len(train_ds)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56a15dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12f3d5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tnet(nn.Module):\n",
    "    def __init__(self, k=35):\n",
    "        super().__init__() \n",
    "        self.k = k \n",
    "        self.conv1 = nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256) \n",
    "        self.fc3 = nn.Linear(256, k*k)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input.shape == (bs, n, 3)\n",
    "        bs = input.size(0)\n",
    "        xb = F.relu(self.bn1(self.conv1(input)))\n",
    "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "        xb = F.relu(self.bn3(self.conv3(xb)))\n",
    "        pool = nn.MaxPool1d(xb.shape[-1]) (xb)\n",
    "        flat = torch.squeeze(pool)\n",
    "        xb = F.relu(self.bn4(self.fc1(flat)))\n",
    "        xb = F.relu(self.bn5(self.fc2(xb)))\n",
    "\n",
    "\n",
    "        # initialize as identity \n",
    "        init = torch.eye(self.k,  requires_grad=True).repeat(bs, 1,1)\n",
    "        if xb.is_cuda:\n",
    "            init = init.cuda() \n",
    "        matrix = self.fc3(xb).view(-1, self.k , self.k) + init \n",
    "        return matrix \n",
    "    \n",
    "\n",
    "class Transform(nn.Module):\n",
    "    def __init__(self, k=35):\n",
    "        super().__init__() \n",
    "        self.k = k\n",
    "        self.input_transform = Tnet(self.k)\n",
    "        self.feature_transform = Tnet(k=64)\n",
    "        self.conv1 = nn.Conv1d(self.k, 64, 1)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        matrix3x3 = self.input_transform(input)\n",
    "        # batch matrix multiplication \n",
    "        xb = torch.bmm(torch.transpose(input, 1, 2), matrix3x3).transpose(1,2)\n",
    "\n",
    "        xb =  F.relu(self.bn1(self.conv1(xb)))\n",
    "\n",
    "        matrix64x64 = self.feature_transform(xb)\n",
    "        xb = torch.bmm(torch.transpose(xb, 1,2), matrix64x64).transpose(1, 2)\n",
    "\n",
    "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "        xb = self.bn3(self.conv3(xb))\n",
    "        xb = nn.MaxPool1d(xb.shape[-1])(xb)\n",
    "        output = torch.squeeze(xb)\n",
    "        return output, matrix3x3, matrix64x64\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, k=35,  output_dim=61):\n",
    "        super().__init__() \n",
    "        self.k = k \n",
    "        self.transform = Transform(self.k) \n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 1024)\n",
    "        self.fc3 = nn.Linear(1024, output_dim)\n",
    "        \n",
    "\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(1024)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, input):\n",
    "        xb, matrix3x3, matrix64x64 = self.transform(input) \n",
    "        xb = F.relu(self.bn1(self.fc1(xb)))\n",
    "        xb = F.relu(self.bn2(self.fc2(xb)))\n",
    "        output = F.relu(self.fc3(xb))\n",
    "        return output \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "292570ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, head_dim):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.head_dim = head_dim \n",
    "        \n",
    "        self.fc1 = nn.Linear(self.head_dim, 2 * self.head_dim)\n",
    "        self.fc2 = nn.Linear(2 * self.head_dim, self.head_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, H, W, num_voxels, dim = x.shape \n",
    "        \n",
    "        scale = np.sqrt( 2 * self.head_dim)\n",
    "        \n",
    "        Query = self.fc1(x)\n",
    "        Key = self.fc1(x)\n",
    "        Value = self.fc1(x)\n",
    "        \n",
    "        attention_weight = (Query @ Key.transpose(3,4)) / scale \n",
    "        attention_weight = F.softmax(attention_weight, dim=-1)\n",
    "        \n",
    "        feature = attention_weight @ Value \n",
    "        \n",
    "        feature = F.relu(self.fc2(feature))\n",
    "        \n",
    "        return feature \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d833a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, num_heads=8, dim=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = int(dim/num_heads)\n",
    "        \n",
    "        self.head1 = AttentionHead(self.head_dim)\n",
    "        self.head2 = AttentionHead(self.head_dim)\n",
    "        self.head3 = AttentionHead(self.head_dim)\n",
    "        self.head4 = AttentionHead(self.head_dim)\n",
    "        self.head5 = AttentionHead(self.head_dim)\n",
    "        self.head6 = AttentionHead(self.head_dim) \n",
    "        self.head7 = AttentionHead(self.head_dim) \n",
    "        self.head8 = AttentionHead(self.head_dim)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm3d(40) \n",
    "        \n",
    "        self.fc1 = nn.Linear(dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, dim)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm3d(40)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, W, H, window_size, window_size, dim = x.shape \n",
    "        x = x.reshape(B, W, H, window_size * window_size, dim)\n",
    "        x = x.reshape(B, W, H, window_size * window_size, self.num_heads, self.head_dim)\n",
    "        x = x.reshape(self.num_heads, B, W, H, window_size * window_size, self.head_dim)\n",
    "        \n",
    "        head1_feature = self.head1(x[0])\n",
    "        head2_feature = self.head2(x[1])\n",
    "        head3_feature = self.head3(x[2])\n",
    "        head4_feature = self.head4(x[3])\n",
    "        head5_feature = self.head5(x[4])\n",
    "        head6_feature = self.head6(x[5])\n",
    "        head7_feature = self.head7(x[6])\n",
    "        head8_feature = self.head8(x[7])\n",
    "        \n",
    "        feature = torch.cat((head1_feature, head2_feature, head3_feature, head4_feature,\n",
    "                             head5_feature, head6_feature, head7_feature, head8_feature), dim=-1)\n",
    "        \n",
    "        #print(\"in multi_head_attention \", feature.shape)\n",
    "        \n",
    "        mh_feature = feature \n",
    "        \n",
    "        # apply batchnorm \n",
    "        feature = self.bn1(feature)\n",
    "        \n",
    "        # apply MLP \n",
    "        \n",
    "        feature = F.relu(self.fc1(feature))\n",
    "        feature = F.relu(self.fc2(feature))\n",
    "        feature = F.relu(self.fc3(feature))\n",
    "        \n",
    "        # Add and Norm \n",
    "        \n",
    "        feature = feature + mh_feature      # residual connection \n",
    "        \n",
    "        feature = self.bn2(feature)\n",
    "        \n",
    "        #print(feature.shape)\n",
    "        \n",
    "        # take the max for global feature of window \n",
    "        global_feature = torch.max(feature, dim=3)[0]\n",
    "        \n",
    "        \n",
    "        #print(\"global dimension\", global_feature.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # convert it into original shape \n",
    "        feature = feature.reshape(B, W, H, window_size, window_size, dim)\n",
    "        \n",
    "        #print(feature.shape)\n",
    "        \n",
    "        return feature, global_feature \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "413d1e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalAttentionHead(nn.Module):\n",
    "    def __init__(self, head_dim):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.head_dim = head_dim \n",
    "        \n",
    "        self.fc1 = nn.Linear(self.head_dim, 2 * self.head_dim)\n",
    "        self.fc2 = nn.Linear(2 * self.head_dim, self.head_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, W, H, dim  = x.shape \n",
    "        \n",
    "        scale = np.sqrt(2 * self.head_dim)\n",
    "        \n",
    "        Query = self.fc1(x)\n",
    "        Key = self.fc1(x)\n",
    "        Value = self.fc1(x)\n",
    "        \n",
    "        attention_weight = (Query @ Key.transpose(2, 3)) / scale \n",
    "        attention_weight = F.softmax(attention_weight, dim=-1)\n",
    "        \n",
    "        feature = attention_weight @ Value \n",
    "        feature = F.relu(self.fc2(feature))\n",
    "        \n",
    "        return feature \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29f46a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalMultiheadAttention(nn.Module):\n",
    "    def __init__(self, num_heads=8, dim=64):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.num_heads = num_heads \n",
    "        self.head_dim = int(dim/self.num_heads) \n",
    "        \n",
    "        \n",
    "        self.head1 = GlobalAttentionHead(self.head_dim)\n",
    "        self.head2 = GlobalAttentionHead(self.head_dim)\n",
    "        self.head3 = GlobalAttentionHead(self.head_dim)\n",
    "        self.head4 = GlobalAttentionHead(self.head_dim)\n",
    "        self.head5 = GlobalAttentionHead(self.head_dim)\n",
    "        self.head6 = GlobalAttentionHead(self.head_dim)\n",
    "        self.head7 = GlobalAttentionHead(self.head_dim)\n",
    "        self.head8 = GlobalAttentionHead(self.head_dim)\n",
    "        \n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(40)\n",
    "        \n",
    "        self.fc1 = nn.Linear(dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, dim)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(40)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, W, H, dim = x.shape \n",
    "        \n",
    "        x = x.reshape(B, W, H, self.num_heads, self.head_dim)\n",
    "        x = x.reshape(self.num_heads, B , W, H, self.head_dim)\n",
    "        \n",
    "        head1_feature = self.head1(x[0])\n",
    "        head2_feature = self.head2(x[1])\n",
    "        head3_feature = self.head3(x[2])\n",
    "        head4_feature = self.head4(x[3])\n",
    "        head5_feature = self.head5(x[4])\n",
    "        head6_feature = self.head6(x[5])\n",
    "        head7_feature = self.head7(x[6])\n",
    "        head8_feature = self.head8(x[7])\n",
    "        \n",
    "        feature = torch.cat((head1_feature, head2_feature, head3_feature, head4_feature, \n",
    "                           head5_feature, head6_feature, head7_feature, head8_feature), dim=-1)\n",
    "        \n",
    "        \n",
    "        mh_feature = feature \n",
    "        \n",
    "        # apply batchnorm \n",
    "        feature = self.bn1(feature)\n",
    "        \n",
    "        # apply mlp \n",
    "        feature = F.relu(self.fc1(feature))\n",
    "        feature = F.relu(self.fc2(feature))\n",
    "        feature = F.relu(self.fc3(feature))\n",
    "        \n",
    "        # add and norm \n",
    "        \n",
    "        feature = feature + mh_feature   # residual connection  \n",
    "        \n",
    "        feature = self.bn2(feature) \n",
    "        \n",
    "        return feature \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "575dbf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.pointnet = PointNet() \n",
    "        \n",
    "        self.multi_head_attention1 = MultiheadAttention(dim=64)\n",
    "        self.global_multi_head_attention1 = GlobalMultiheadAttention(dim=64)\n",
    "        \n",
    "        self.multi_head_attention2 = MultiheadAttention(dim=64 * 2)\n",
    "        self.global_multi_head_attention2 = GlobalMultiheadAttention(dim=64 * 2)\n",
    "        \n",
    "        self.multi_head_attention3 = MultiheadAttention(dim=64 * 2 * 2)\n",
    "        self.global_multi_head_attention3 = GlobalMultiheadAttention(dim=64 * 2 * 2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x, coors):\n",
    "        B, Voxels, max_points, dim = x.shape\n",
    "        x = x.reshape(-1, max_points, dim)\n",
    "        \n",
    "        # send to pointnet\n",
    "        x = self.pointnet(x).unsqueeze(0)\n",
    "    \n",
    "        # concatenation of voxel coordinate with voxel features ( positional embedding)\n",
    "        x = torch.cat((x, coors), 2).reshape(1, 200, 100, 64)\n",
    "        B, H, W ,  dim = x.shape \n",
    "        # divide into window of size 5 * 5 \n",
    "        x = x.reshape(B, int(H/5), int(W/5), 5, 5, dim)\n",
    "        \n",
    "        # apply attention block 1\n",
    "        feature, global_feature = self.multi_head_attention1(x)\n",
    "        # apply global attention-block\n",
    "        global_feature = self.global_multi_head_attention1(global_feature)\n",
    "        global_feature = global_feature.unsqueeze(3).unsqueeze(3)\n",
    "        # repeat tensor \n",
    "        global_feature = global_feature.repeat(1, 1, 1, 5, 5, 1)\n",
    "        # add global feature with local features \n",
    "        feature = torch.cat((feature, global_feature), dim=-1) \n",
    "        \n",
    "        \n",
    "        \n",
    "        # apply attention block 2 \n",
    "        feature, global_feature = self.multi_head_attention2(feature)\n",
    "        # apply global attention block \n",
    "        global_feature = self.global_multi_head_attention2(global_feature)\n",
    "        global_feature = global_feature.unsqueeze(3).unsqueeze(3)\n",
    "        # repeat tensor \n",
    "        global_feature = global_feature.repeat(1,1,1,5,5,1)\n",
    "        # add global feaeture with local features \n",
    "        feature = torch.cat((feature, global_feature), dim=-1)\n",
    "        \n",
    "        \n",
    "        # apply attention block 3 \n",
    "        feature, global_feature = self.multi_head_attention3(feature)\n",
    "        # apply globla attenion block \n",
    "        global_feature = self.global_multi_head_attention3(global_feature)\n",
    "        global_feature = global_feature.unsqueeze(3).unsqueeze(3)\n",
    "        # repeat tensor \n",
    "        global_feature = global_feature.repeat(1,1,1,5,5,1)\n",
    "        # add global feature with local features \n",
    "        feature = torch.cat((feature, global_feature), dim=-1) \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return feature \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18216167",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionAttention(nn.Module):\n",
    "    def __init__(self, head_dim):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.head_dim = head_dim \n",
    "        self.fc1 = nn.Linear(self.head_dim, 2 * self.head_dim)\n",
    "        self.fc2 = nn.Linear(2*self.head_dim , self.head_dim)\n",
    "        \n",
    "    def forward(self, query, key, value):\n",
    "        \n",
    "        scale = np.sqrt(self.head_dim)\n",
    "        \n",
    "        Query = self.fc1(query)\n",
    "        Key = self.fc1(key)\n",
    "        Value = self.fc1(value)\n",
    "        \n",
    "        attention_weight = (Query @ Key.transpose(3, 4)) / scale \n",
    "        attention_weight = F.softmax(attention_weight, dim=-1)\n",
    "        \n",
    "        feature = attention_weight @ Value \n",
    "        feature = self.fc2(feature)\n",
    "        return feature \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc97b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrelationAttentionHead(nn.Module):\n",
    "    def __init__(self, num_head=8, dim=512):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.num_head = num_head \n",
    "        self.head_dim = int(dim/self.num_head)\n",
    "        \n",
    "        \n",
    "        self.head1 = FusionAttention(self.head_dim)\n",
    "        self.head2 = FusionAttention(self.head_dim)\n",
    "        self.head3 = FusionAttention(self.head_dim)\n",
    "        self.head4 = FusionAttention(self.head_dim)\n",
    "        self.head5 = FusionAttention(self.head_dim)\n",
    "        self.head6 = FusionAttention(self.head_dim)\n",
    "        self.head7 = FusionAttention(self.head_dim)\n",
    "        self.head8 = FusionAttention(self.head_dim)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm3d(40)\n",
    "        \n",
    "        self.fc1 = nn.Linear(dim, 2 * dim)\n",
    "        self.fc2 = nn.Linear(2 * dim, 3 * dim)\n",
    "        self.fc3 = nn.Linear(3 * dim, dim)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm3d(40)\n",
    "        \n",
    "    def forward(self, current_x, past_x):\n",
    "        c_B, c_W, c_H, c_window_size, c_window_size, c_dim = current_x.shape \n",
    "        p_B, p_W, p_H, p_window_size, p_window_size, p_dim = past_x.shape \n",
    "        \n",
    "        # change shape \n",
    "        current_x = current_x.reshape(c_B, c_W, c_H, c_window_size * c_window_size, c_dim)\n",
    "        past_x = past_x.reshape(p_B, p_W, p_H, p_window_size * p_window_size, p_dim)\n",
    "        \n",
    "        Query = current_x.reshape(c_B, c_W, c_H, c_window_size * c_window_size, self.num_head, self.head_dim)\n",
    "        Query = current_x.reshape(self.num_head, c_B, c_W, c_H, c_window_size*c_window_size, self.head_dim)\n",
    "        \n",
    "        Key = past_x.reshape(p_B, p_W, p_H, p_window_size * p_window_size, self.num_head, self.head_dim)\n",
    "        Key = past_x.reshape(self.num_head, p_B, p_W, p_H, p_window_size*p_window_size, self.head_dim)\n",
    "        Value = Key \n",
    "        \n",
    "        head1_feature = self.head1(Query[0], Key[0], Value[0])\n",
    "        head2_feature = self.head2(Query[1], Key[1], Value[1])\n",
    "        head3_feature = self.head3(Query[2], Key[2], Value[2])\n",
    "        head4_feature = self.head4(Query[3], Key[3], Value[3])\n",
    "        head5_feature = self.head5(Query[4], Key[4], Value[4])\n",
    "        head6_feature = self.head6(Query[5], Key[5], Value[5])\n",
    "        head7_feature = self.head7(Query[6], Key[6], Value[6])\n",
    "        head8_feature = self.head8(Query[7], Key[7], Value[7])\n",
    "        \n",
    "        feature = torch.cat((head1_feature, head2_feature, head3_feature, head4_feature,\n",
    "                            head5_feature, head6_feature, head7_feature, head8_feature), dim=-1)\n",
    "        \n",
    "        \n",
    "        mh_feature = feature \n",
    "        \n",
    "        # apply batchnorm \n",
    "        feature = self.bn1(feature)\n",
    "        \n",
    "        # apply mlp \n",
    "        feature = F.relu(self.fc1(feature))\n",
    "        feature = F.relu(self.fc2(feature))\n",
    "        feature = F.relu(self.fc3(feature))\n",
    "        \n",
    "        # add and norm \n",
    "        feature = feature + mh_feature    # residual connections \n",
    "        \n",
    "        feature = self.bn2(feature)\n",
    "        \n",
    "        # convert it into original shape\n",
    "        feature = feature.reshape(c_B, c_W, c_H, c_window_size, c_window_size, c_dim)\n",
    "        \n",
    "        return feature  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0b171fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.encoder = TransformerEncoder()\n",
    "        \n",
    "        self.correlationModule = CorrelationAttentionHead() \n",
    "        \n",
    "        self.past_frame_features = 0\n",
    "        \n",
    "        # make displacement head \n",
    "        self.fc_d1 = nn.Linear(512, 1024)\n",
    "        self.fc_d2 = nn.Linear(1024, 2024)\n",
    "        self.fc_d3 = nn.Linear(2024, 3 * 80*70)\n",
    "        \n",
    "        # meke score head \n",
    "        self.fc_s1 = nn.Linear(512, 1024)\n",
    "        self.fc_s2 = nn.Linear(1024, 2024)\n",
    "        self.fc_s3 = nn.Linear(2024, 80*70)\n",
    "        \n",
    "        # make detection_head \n",
    "        self.fc_cent1 = nn.Linear(512, 1024)\n",
    "        self.fc_cent2 = nn.Linear(1024, 2024)\n",
    "        self.fc_cent3 = nn.Linear(2024, 80*70*3)\n",
    "        \n",
    "        # make coordinate prediction head \n",
    "        self.fc_coord1 = nn.Linear(512, 1024)\n",
    "        self.fc_coord2 = nn.Linear(1024, 2024)\n",
    "        self.fc_coord3 = nn.Linear(2024, 80*70*8*3)\n",
    "        \n",
    "        # make classification_head \n",
    "        self.fc_cl1 = nn.Linear(512, 1024)\n",
    "        self.fc_cl2 = nn.Linear(1024, 2024)\n",
    "        self.fc_cl3 = nn.Linear(2024, 80*70*10) \n",
    "        \n",
    "        # make rotation prediction head \n",
    "        \n",
    "        self.fc_rot1 = nn.Linear(512, 1024)\n",
    "        self.fc_rot2 = nn.Linear(1024, 2024)\n",
    "        self.fc_rot3 = nn.Linear(2024, 80*70)\n",
    "        \n",
    "        \n",
    "        \n",
    "      \n",
    "        \n",
    "    def forward(self, voxels, coors, n):\n",
    "        num_frames = n+1                        # for tracking frame number\n",
    "        # apply encoder module \n",
    "        features = self.encoder(voxels, coors)\n",
    "        \n",
    "        \n",
    "        # apply correlation fusion module\n",
    "        \n",
    "        if num_frames == 1:\n",
    "            correlated_features = self.correlationModule(features, features)   # current_x and past_x are  same for end to end training\n",
    "            self.past_frame_features= features # make current frame features as a past frame features.\n",
    "        else:\n",
    "            correlated_features = self.correlationModule(features, self.past_frame_features)\n",
    "            self.past_frame_features = features #make current frame features as a past frame features.\n",
    "            \n",
    "            \n",
    "        \n",
    "        # take max pool for all voxel features for redusing number of features amd number of model parameters\n",
    "        \n",
    "        features = features.reshape(1, -1, 512).max(1, keepdim=True)[0]\n",
    "        correlated_features = correlated_features.reshape(1, -1, 512).max(1, keepdim=True)[0]\n",
    "        \n",
    "        # apply displacement head \n",
    "        displacement = F.relu(self.fc_d1(correlated_features))\n",
    "        displacement = F.relu(self.fc_d2(displacement))\n",
    "        displacement = self.fc_d3(displacement).reshape(1, 3, 80, 70)\n",
    "        \n",
    "        # apply score head \n",
    "        score = F.relu(self.fc_s1(features))\n",
    "        score = F.relu(self.fc_s2(score))\n",
    "        score = self.fc_s3(score).reshape(1, 80, 70)\n",
    "        \n",
    "        # apply detection head \n",
    "        detection = F.relu(self.fc_cent1(features))\n",
    "        detection = F.relu(self.fc_cent2(detection))\n",
    "        detection = self.fc_cent3(detection).reshape(1, 3, 80, 70)\n",
    "        \n",
    "        # apply coordinate prediction head \n",
    "        coordinate = F.relu(self.fc_coord1(features))\n",
    "        coordinate = F.relu(self.fc_coord2(coordinate))\n",
    "        coordinate = self.fc_coord3(coordinate).reshape(1, 8*3, 80, 70)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # apply classification head \n",
    "        classification = F.relu(self.fc_cl1(features))\n",
    "        classification = F.relu(self.fc_cl2(classification))\n",
    "        classification = self.fc_cl3(classification).reshape(1, 10, 80, 70)\n",
    "        \n",
    "        # apply rotation prediction head \n",
    "        rot = F.relu(self.fc_rot1(features)) \n",
    "        rot = F.relu(self.fc_rot2(rot))\n",
    "        rot = self.fc_rot3(rot).reshape(1, 80, 70)\n",
    "        \n",
    "        \n",
    "        return displacement, score, detection, coordinate, classification, rot\n",
    "           \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f22b204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(input, target, gamma):\n",
    "    ce = F.cross_entropy(input, target, reduction='none')\n",
    "    pt = torch.exp(-ce)\n",
    "\n",
    "    focal_loss = (1 - pt)**gamma * ce \n",
    "\n",
    "    # take sum of focal loss of all classes \n",
    "    focal_loss = focal_loss.sum()\n",
    "\n",
    "    return focal_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb57f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb9e5b1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc07dcb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m StepLR(\u001b[43moptimizer\u001b[49m, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74f6cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fece198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epoch):\n",
    "    for i in range(epoch):\n",
    "        running_loss = 0.0 \n",
    "        global past_canters \n",
    "        past_centers = 0\n",
    "        for n, data in enumerate(train_loader):\n",
    "            loss = 0.0\n",
    "            if n == 0:\n",
    "                voxels = data['voxels'].to(device).float()\n",
    "                coors = data['coors'].to(device).float()\n",
    "                bboxes = data['bboxes']\n",
    "                \n",
    "                # store centers, bboxes \n",
    "                centers = []\n",
    "                coordinates = []\n",
    "                rot = [] \n",
    "                ids = [] \n",
    "                category = [] \n",
    "                \n",
    "                for l in range(len(bboxes)):\n",
    "                    centers.append(bboxes[l][0][0])\n",
    "                    coordinates.append(bboxes[l][1][0].reshape(1, -1)[0])\n",
    "                    rot.append(bboxes[l][2][0])\n",
    "                    category.append(bboxes[l][3][0])\n",
    "                    ids.append(bboxes[l][4][0])\n",
    "                    \n",
    "                #print(\"centers = \", centers)\n",
    "                #print(\"coordinates = \", coordinates[0])\n",
    "                #print(\"rot=\",rot[0].item())\n",
    "                #print(\"ids=\", ids)\n",
    "                #print(\"category=\",category[0])\n",
    "                                    \n",
    "                # send input to the model\n",
    "                displacement_pred, score_pred, detection_pred, coordinate_pred, classification_pred, rot_pred = model(voxels, coors, n) \n",
    "                \n",
    "                displacement_target = torch.zeros(displacement_pred.shape).to(device)\n",
    "                score_target = torch.zeros(score_pred.shape).to(device)\n",
    "                detection_target = torch.zeros(detection_pred.shape).to(device)\n",
    "                coordinate_target = torch.zeros(coordinate_pred.shape).to(device)\n",
    "                classification_target = torch.zeros(classification_pred.shape).to(device)\n",
    "                rot_target = torch.zeros(rot_pred.shape).to(device)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                for l in range(len(centers)):\n",
    "                    center = torch.round(centers[l])\n",
    "                    x = center[0].item()\n",
    "                    y = center[1].item()\n",
    "                     \n",
    "                    if x >= 70 or y > 40 or y <= -40:      # delete all annotation outside the range\n",
    "                        continue \n",
    "                        \n",
    "                    x = int(x)\n",
    "                    if y < 0:\n",
    "                        y = abs(y) + 40 \n",
    "                        y = int(y)\n",
    "                    else:\n",
    "                        y = int(y) \n",
    "                        \n",
    "                    score_target[0][y][x] = 1      # y , x locate the location on output grid \n",
    "                    \n",
    "                    # get the center location of BB\n",
    "                    center_bb = centers[l]\n",
    "                    center_x = center_bb[0].item()\n",
    "                    center_y = center_bb[1].item()\n",
    "                    center_z = center_bb[2].item()\n",
    "                    \n",
    "                    detection_target[0][0][y][x] = center_x \n",
    "                    detection_target[0][1][y][x] = center_y \n",
    "                    detection_target[0][2][y][x] = center_z \n",
    "                    \n",
    "                    \n",
    "                    for k in range(24):\n",
    "                        coordinate_target[0][k][y][x] = coordinates[l][k]\n",
    "                        \n",
    "                    # 'Car'->0, 'Van'->1, 'Truck'->2, 'Pedestrian'->3, 'Person_sitting'->4, 'Cyclist'->5, \n",
    "                    #'Tram'->6, 'Misc'->7, 'Person'->8, 'Background'->9 \n",
    "                    \n",
    "                    if category[l] == 'Car':\n",
    "                        classification_target[0][0][y][x] = 1 \n",
    "                    if category[l] == 'Van':\n",
    "                        classification_target[0][1][y][x] = 1 \n",
    "                    if category[l] == 'Truck':\n",
    "                        classification_target[0][2][y][x] = 1 \n",
    "                    if category[l] == 'Pedestrian':\n",
    "                        classification_target[0][3][y][x] = 1 \n",
    "                    if category[l] == 'Person_sitting':\n",
    "                        classification_target[0][4][y][x] = 1 \n",
    "                    if category[l] == 'Cyclist':\n",
    "                        classification_target[0][5][y][x] = 1 \n",
    "                    if category[l] == 'Tram':\n",
    "                        classification_target[0][6][y][x] = 1 \n",
    "                    if category[l] == 'Misc':\n",
    "                        classification_target[0][7][y][x] = 1 \n",
    "                    if category[l] == 'Person':\n",
    "                        classification_target[0][8][y][x] = 1 \n",
    "                     \n",
    "                    #  add one at background (complementation)\n",
    "                    classification_target[0][9][y][x] = 1 \n",
    "                    # prepare rot_target \n",
    "                    rot_target[0][y][x] = rot[l].item()\n",
    "                    \n",
    "                # correct background class  \n",
    "                \n",
    "                for k in  range(80):\n",
    "                    for j in range(70):\n",
    "                        if classification_target[0][9][k][j] == 1:\n",
    "                            classification_target[0][9][k][j] = 0 \n",
    "                        else:\n",
    "                            classification_target[0][9][k][j] = 1 \n",
    "               \n",
    "                # calculate loss \n",
    "                displacement_loss = ((displacement_pred - displacement_target)**2).sum()\n",
    "                # calculate score loss \n",
    "                score_loss = ((score_pred - score_target) ** 2).sum()\n",
    "                # calculate detection loss \n",
    "                detection_loss = ((detection_pred - detection_target)**2).sum()\n",
    "                # calculate coordinate loss \n",
    "                coordinate_loss = ((coordinate_pred - coordinate_target)**2).sum() \n",
    "                # rotation loss \n",
    "                rot_loss = ((rot_pred - rot_target)**2).sum()\n",
    "                # calculate classification loss using focal loss function \n",
    "                classification_loss = focal_loss(classification_pred, classification_target, 2)\n",
    "                \n",
    "                loss = loss + 1* classification_loss + 2 * detection_loss + 2 * coordinate_loss + 2 * score_loss + 2 * rot_loss + displacement_loss \n",
    "                \n",
    "                # apply backprop \n",
    "                optimizer.zero_grad() \n",
    "                loss.backward(retain_graph=True) \n",
    "                \n",
    "                # print gradient \n",
    "                for name, param in model.named_parameters():\n",
    "                    print(name, param.grad)\n",
    "                    \n",
    "                \n",
    "                \n",
    "                optimizer.step() \n",
    "                \n",
    "                scheduler.step()\n",
    "                \n",
    "                running_loss = running_loss + loss.item() \n",
    "                \n",
    "                # assign current detection target to past_centers\n",
    "                past_centers = detection_target \n",
    "                \n",
    "                \n",
    "                del loss, displacement_loss, score_loss, detection_loss, coordinate_loss, rot_loss, classification_loss \n",
    "                del displacement_pred, score_pred, detection_pred, coordinate_pred, classification_pred, rot_pred \n",
    "                del displacement_target, score_target, detection_target, coordinate_target, classification_target, rot_target \n",
    "                \n",
    "                     \n",
    "            else:\n",
    "                voxels = data['voxels'].to(device).float()\n",
    "                coors = data['coors'].to(device).float()\n",
    "                bboxes = data['bboxes']\n",
    "                \n",
    "                # store centers, bboxes \n",
    "                centers = []\n",
    "                coordinates = []\n",
    "                rot = [] \n",
    "                ids = [] \n",
    "                category = [] \n",
    "                \n",
    "                for l in range(len(bboxes)):\n",
    "                    centers.append(bboxes[l][0][0])\n",
    "                    coordinates.append(bboxes[l][1][0].reshape(1, -1)[0])\n",
    "                    rot.append(bboxes[l][2][0])\n",
    "                    category.append(bboxes[l][3][0])\n",
    "                    ids.append(bboxes[l][4][0])\n",
    "                    \n",
    "                #print(\"centers = \", centers)\n",
    "                #print(\"coordinates = \", coordinates[0])\n",
    "                #print(\"rot=\",rot[0].item())\n",
    "                #print(\"ids=\", ids)\n",
    "                #print(\"category=\",category[0])\n",
    "                                    \n",
    "                # send input to the model\n",
    "                displacement_pred, score_pred, detection_pred, coordinate_pred, classification_pred, rot_pred = model(voxels, coors, n) \n",
    "                \n",
    "                #displacement_target = torch.zeros(displacement_pred.shape).to(device)\n",
    "                score_target = torch.zeros(score_pred.shape).to(device)\n",
    "                detection_target = torch.zeros(detection_pred.shape).to(device)\n",
    "                coordinate_target = torch.zeros(coordinate_pred.shape).to(device)\n",
    "                classification_target = torch.zeros(classification_pred.shape).to(device)\n",
    "                rot_target = torch.zeros(rot_pred.shape).to(device)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                for l in range(len(centers)):\n",
    "                    center = torch.round(centers[l])\n",
    "                    x = center[0].item()\n",
    "                    y = center[1].item()\n",
    "                     \n",
    "                    if x >= 70 or y > 40 or y <= -40:      # delete all annotation outside the range\n",
    "                        continue \n",
    "                        \n",
    "                    x = int(x)\n",
    "                    if y < 0:\n",
    "                        y = abs(y) + 40 \n",
    "                        y = int(y)\n",
    "                    else:\n",
    "                        y = int(y) \n",
    "                        \n",
    "                    score_target[0][y][x] = 1      # y , x locate the location on output grid \n",
    "                    \n",
    "                    # get the center location of BB\n",
    "                    center_bb = centers[l]\n",
    "                    center_x = center_bb[0].item()\n",
    "                    center_y = center_bb[1].item()\n",
    "                    center_z = center_bb[2].item()\n",
    "                    \n",
    "                    detection_target[0][0][y][x] = center_x \n",
    "                    detection_target[0][1][y][x] = center_y \n",
    "                    detection_target[0][2][y][x] = center_z \n",
    "                    \n",
    "                    \n",
    "                    for k in range(24):\n",
    "                        coordinate_target[0][k][y][x] = coordinates[l][k]\n",
    "                        \n",
    "                    # 'Car'->0, 'Van'->1, 'Truck'->2, 'Pedestrian'->3, 'Person_sitting'->4, 'Cyclist'->5, \n",
    "                    #'Tram'->6, 'Misc'->7, 'Person'->8, 'Background'->9 \n",
    "                    \n",
    "                    if category[l] == 'Car':\n",
    "                        classification_target[0][0][y][x] = 1 \n",
    "                    if category[l] == 'Van':\n",
    "                        classification_target[0][1][y][x] = 1 \n",
    "                    if category[l] == 'Truck':\n",
    "                        classification_target[0][2][y][x] = 1 \n",
    "                    if category[l] == 'Pedestrian':\n",
    "                        classification_target[0][3][y][x] = 1 \n",
    "                    if category[l] == 'Person_sitting':\n",
    "                        classification_target[0][4][y][x] = 1 \n",
    "                    if category[l] == 'Cyclist':\n",
    "                        classification_target[0][5][y][x] = 1 \n",
    "                    if category[l] == 'Tram':\n",
    "                        classification_target[0][6][y][x] = 1 \n",
    "                    if category[l] == 'Misc':\n",
    "                        classification_target[0][7][y][x] = 1 \n",
    "                    if category[l] == 'Person':\n",
    "                        classification_target[0][8][y][x] = 1 \n",
    "                     \n",
    "                    #  add one at background (complementation)\n",
    "                    classification_target[0][9][y][x] = 1 \n",
    "                    # prepare rot_target \n",
    "                    rot_target[0][y][x] = rot[l].item()\n",
    "                    \n",
    "                # correct background class  \n",
    "                \n",
    "                for k in  range(80):\n",
    "                    for j in range(70):\n",
    "                        if classification_target[0][9][k][j] == 1:\n",
    "                            classification_target[0][9][k][j] = 0 \n",
    "                        else:\n",
    "                            classification_target[0][9][k][j] = 1 \n",
    "                \n",
    "                \n",
    "                # calculate displacement_target \n",
    "                displacement_target = detection_target - past_centers \n",
    "                \n",
    "                \n",
    "                # calculate loss \n",
    "                displacement_loss = ((displacement_pred - displacement_target)**2).sum()\n",
    "                # calculate score loss \n",
    "                score_loss = ((score_pred - score_target) ** 2).sum()\n",
    "                # calculate detection loss \n",
    "                detection_loss = ((detection_pred - detection_target)**2).sum()\n",
    "                # calculate coordinate loss \n",
    "                coordinate_loss = ((coordinate_pred - coordinate_target)**2).sum() \n",
    "                # rotation loss \n",
    "                rot_loss = ((rot_pred - rot_target)**2).sum()\n",
    "                # calculate classification loss using focal loss function \n",
    "                classification_loss = focal_loss(classification_pred, classification_target, 2)\n",
    "                \n",
    "                loss = loss + 1* classification_loss + 2 * detection_loss + 2 * coordinate_loss + 2 * score_loss + 2 * rot_loss + displacement_loss \n",
    "                \n",
    "                # apply backprop \n",
    "                optimizer.zero_grad() \n",
    "                loss.backward(retain_graph=True) \n",
    "                # print gradient\n",
    "                for name, param in model.named_parameters():\n",
    "                    print(name, param.grad)\n",
    "                \n",
    "                optimizer.step() \n",
    "                \n",
    "                scheduler.step()\n",
    "                \n",
    "                \n",
    "                running_loss = running_loss + loss.item() \n",
    "                \n",
    "                # assign current detection_tartget to past_centers\n",
    "                past_centers = detection_target\n",
    "                \n",
    "                \n",
    "                del loss, displacement_loss, score_loss, detection_loss, coordinate_loss, rot_loss, classification_loss \n",
    "                del displacement_pred, score_pred, detection_pred, coordinate_pred, classification_pred, rot_pred \n",
    "                del displacement_target, score_target, detection_target, coordinate_target, classification_target, rot_target \n",
    "        \n",
    "        epoch_loss.append(running_loss)\n",
    "        print(\" epoch = {} , running_loss = {}\".format(i+1, running_loss))\n",
    "        \n",
    "        checkpoint = {\n",
    "            \"epoch_number\" : i+1,\n",
    "            \"model_state\" : model.state_dict()\n",
    "        }\n",
    "        torch.save(checkpoint, \"tracking_model2.pth\") \n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576ffe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_loader, 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
